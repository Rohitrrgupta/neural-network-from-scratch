{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f364d8",
   "metadata": {},
   "source": [
    "# Simple MNIST NN from scratch\n",
    "\n",
    "In this notebook, I implemented a simple three-layer neural network and trained it on the MNIST alphabet recognizer dataset from scratch using only numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8048b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required datasets\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "X_train, y_train = extract_training_samples('letters')\n",
    "X_test, y_test = extract_test_samples('letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bed37f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96dc5347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124800, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1931436",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], -1)) / 255\n",
    "\n",
    "X_test = X_test.reshape((X_test.shape[0], -1)) / 255\n",
    "\n",
    "m, n = X_train.shape\n",
    "\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339d22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 124800)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f6132f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d4611",
   "metadata": {},
   "source": [
    "Our NN will have a simple three-layer architecture. Input layer $a^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28x28 input image. Hidden layers $a^{[1]}$ will have 128 units with ReLU activation, and finally our output layer $a^{[2]}$ will have 26 units corresponding to the 26 alphabet classes with softmax activation.\n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]})$$\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
    "$$Z^{[3]} = W^{[3]} A^{[2]} + b^{[3]}$$\n",
    "$$A^{[3]} = g_{\\text{softmax}}(Z^{[3]})$$\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "$$dZ^{[3]} = A^{[3]} - Y$$\n",
    "$$dW^{[3]} = \\frac{1}{m} dZ^{[3]} A^{[2]T}$$\n",
    "$$dB^{[3]} = \\frac{1}{m} \\Sigma {dZ^{[3]}}$$\n",
    "$$dZ^{[2]} = W^{[3]T} dZ^{[3]} . g^{[2]\\prime} (z^{[2]})$$\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
    "$$dB^{[2]} = \\frac{1}{m} \\Sigma {dZ^{[2]}}$$\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} {X}^{T}$$\n",
    "$$dB^{[1]} = \\frac{1}{m} \\Sigma {dZ^{[1]}}$$\n",
    "\n",
    "**Parameter updates**\n",
    "\n",
    "$$W^{[3]} := W^{[3]} - \\alpha dW^{[3]}$$\n",
    "$$b^{[3]} := b^{[3]} - \\alpha db^{[3]}$$\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
    "\n",
    "**Vars and shapes**\n",
    "\n",
    "Forward prop\n",
    "\n",
    "- $A^{[0]} = X$: 784 x m\n",
    "- $Z^{[1]} \\sim A^{[1]}$: 128 x m\n",
    "- $W^{[1]}$: 128 x 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)\n",
    "- $B^{[1]}$: 128 x 1\n",
    "- $Z^{[2]} \\sim A^{[2]}$: 128 x m\n",
    "- $W^{[2]}$: 128 x 128 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
    "- $B^{[2]}$: 128 x 1\n",
    "- $Z^{[3]} \\sim A^{[2]}$: 26 x m\n",
    "- $W^{[3]}$: 26 x 128 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
    "- $B^{[3]}$: 26 x 1\n",
    "\n",
    "Backprop\n",
    "\n",
    "- $dZ^{[3]}$: 26 x m ($~A^{[2]}$)\n",
    "- $dW^{[3]}$: 26 x 128\n",
    "- $dB^{[3]}$: 26 x 1\n",
    "- $dZ^{[2]}$: 128 x m ($~A^{[2]}$)\n",
    "- $dW^{[2]}$: 128 x 128\n",
    "- $dB^{[2]}$: 128 x 1\n",
    "- $dZ^{[1]}$: 128 x m ($~A^{[1]}$)\n",
    "- $dW^{[1]}$: 128 x 784\n",
    "- $dB^{[1]}$: 128 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31010656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    w1 = np.random.rand(128, 784) - 0.5\n",
    "    b1 = np.random.rand(128, 1) - 0.5\n",
    "    w2 = np.random.rand(128, 128) - 0.5\n",
    "    b2 = np.random.rand(128, 1) - 0.5\n",
    "    w3 = np.random.rand(26, 128) - 0.5\n",
    "    b3 = np.random.rand(26, 1) - 0.5\n",
    "    return w1, b1, w2, b2, w3, b3\n",
    "\n",
    "def ReLU(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "def softmax(z):\n",
    "    a = np.exp(z) / sum(np.exp(z))\n",
    "    return a\n",
    "\n",
    "def forward_prop(w1, b1, w2, b2, w3, b3, X):\n",
    "    z1 = w1.dot(X) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = ReLU(z2)\n",
    "    z3 = w3.dot(a2) + b3\n",
    "    a3 = softmax(z3)\n",
    "    return z1, a1, z2, a2, z3, a3\n",
    "\n",
    "def one_hot(y):\n",
    "    one_hot_y = np.zeros((y.size, y.max() + 1))\n",
    "    one_hot_y[np.arange(y.size), y] = 1\n",
    "    one_hot_y = one_hot_y.T\n",
    "    return one_hot_y\n",
    "\n",
    "def deriv_ReLU(z):\n",
    "    return z > 0\n",
    "\n",
    "def compute_reg_term(w1, w2, w3, lambd, m):\n",
    "    reg_term = (lambd / (2*m)) * (np.sum(w1**2) + np.sum(w2**2) + np.sum(w3**2))\n",
    "    return reg_term\n",
    "    \n",
    "def back_prop(z1, a1, z2, a2, z3, a3, w1, w2, w3, X, y, lambd, m):\n",
    "    one_hot_y = one_hot(y)\n",
    "    dz3 = a3 - one_hot_y\n",
    "    dw3 = (1/m * dz3.dot(a2.T)) + ((lambd/m) * w3)\n",
    "    db3 = 1/m * np.sum(dz3, axis=1, keepdims=True)\n",
    "    \n",
    "    dz2 = w3.T.dot(dz3) * deriv_ReLU(z2)\n",
    "    dw2 = (1/m * dz2.dot(a1.T)) + ((lambd/m) * w2)\n",
    "    db2 = 1/m * np.sum(dz2, axis=1, keepdims=True)\n",
    "    \n",
    "    dz1 = w2.T.dot(dz2) * deriv_ReLU(z1)\n",
    "    dw1 = (1/m * dz1.dot(X.T)) + ((lambd/m) * w1)\n",
    "    db1 = 1/m * np.sum(dz1, axis=1, keepdims=True)\n",
    "    return dw1, db1, dw2, db2, dw3, db3\n",
    "\n",
    "def update_params(w1, b1, w2, b2, w3, b3, dw1, db1, dw2, db2, dw3, db3, alpha):\n",
    "    w1 = w1 - alpha * dw1\n",
    "    b1 = b1 - alpha * db1\n",
    "    w2 = w2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    w3 = w3 - alpha * dw3\n",
    "    b3 = b3 - alpha * db3\n",
    "    return w1, b1, w2, b2, w3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c4a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(a3):\n",
    "    return np.argmax(a3, axis = 0)\n",
    "\n",
    "def get_accuracy(predictions, y):\n",
    "    print(predictions, y)\n",
    "    return np.sum(predictions == y) / y.size\n",
    "\n",
    "def gradient_descent(X, y, alpha, lambd, iterations):\n",
    "    w1, b1, w2, b2, w3, b3 = init_params()\n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2, z3, a3 = forward_prop(w1, b1, w2, b2, w3, b3, X)\n",
    "        dw1, db1, dw2, db2, dw3, db3 = back_prop(z1, a1, z2, a2, z3, a3, w1, w2, w3, X, y, lambd, m)\n",
    "        w1, b1, w2, b2, w3, b3 = update_params(w1, b1, w2, b2, w3, b3, dw1, db1, dw2, db2, dw3, db3, alpha)\n",
    "        if i % 20 == 0:\n",
    "            print('Iteration:', i)\n",
    "            predictions = get_predictions(a3)\n",
    "            print(get_accuracy(predictions, y))\n",
    "    return w1, b1, w2, b2, w3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db20bafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "[17  8 17 ... 13 22 13] [22  6 15 ... 12 14 18]\n",
      "0.03403846153846154\n",
      "Iteration: 20\n",
      "[25 18  5 ... 25 14 18] [22  6 15 ... 12 14 18]\n",
      "0.2627403846153846\n",
      "Iteration: 40\n",
      "[25 18 15 ... 25 14 18] [22  6 15 ... 12 14 18]\n",
      "0.3537419871794872\n",
      "Iteration: 60\n",
      "[25  6 15 ... 25 14 18] [22  6 15 ... 12 14 18]\n",
      "0.4167628205128205\n",
      "Iteration: 80\n",
      "[25  6 15 ... 25 14 18] [22  6 15 ... 12 14 18]\n",
      "0.4609935897435897\n",
      "Iteration: 100\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.49451121794871794\n",
      "Iteration: 120\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.5204807692307692\n",
      "Iteration: 140\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.5414262820512821\n",
      "Iteration: 160\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.5595352564102564\n",
      "Iteration: 180\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.5758974358974359\n",
      "Iteration: 200\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.589551282051282\n",
      "Iteration: 220\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6014983974358974\n",
      "Iteration: 240\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6118349358974359\n",
      "Iteration: 260\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6222836538461538\n",
      "Iteration: 280\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.631201923076923\n",
      "Iteration: 300\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6389423076923076\n",
      "Iteration: 320\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6461939102564103\n",
      "Iteration: 340\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6529567307692308\n",
      "Iteration: 360\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6597435897435897\n",
      "Iteration: 380\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.665584935897436\n",
      "Iteration: 400\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6709455128205128\n",
      "Iteration: 420\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6757932692307692\n",
      "Iteration: 440\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6807852564102564\n",
      "Iteration: 460\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6854086538461538\n",
      "Iteration: 480\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6901121794871795\n",
      "Iteration: 500\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6941826923076924\n",
      "Iteration: 520\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.6980608974358974\n",
      "Iteration: 540\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7014262820512821\n",
      "Iteration: 560\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7052083333333333\n",
      "Iteration: 580\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7086698717948718\n",
      "Iteration: 600\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7121314102564102\n",
      "Iteration: 620\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7153685897435897\n",
      "Iteration: 640\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7183814102564102\n",
      "Iteration: 660\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7211378205128205\n",
      "Iteration: 680\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7240224358974359\n",
      "Iteration: 700\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7265064102564103\n",
      "Iteration: 720\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7289983974358974\n",
      "Iteration: 740\n",
      "[10  6 15 ...  4 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7315544871794872\n",
      "Iteration: 760\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7338141025641025\n",
      "Iteration: 780\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7359615384615384\n",
      "Iteration: 800\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7386458333333333\n",
      "Iteration: 820\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.740849358974359\n",
      "Iteration: 840\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7428846153846154\n",
      "Iteration: 860\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7447676282051282\n",
      "Iteration: 880\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7464342948717949\n",
      "Iteration: 900\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7484935897435897\n",
      "Iteration: 920\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7503044871794872\n",
      "Iteration: 940\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7518189102564102\n",
      "Iteration: 960\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7536698717948718\n",
      "Iteration: 980\n",
      "[10  6 15 ... 13 14 18] [22  6 15 ... 12 14 18]\n",
      "0.7552483974358974\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2, w3, b3 = gradient_descent(X_train, y_train, 0.1, 0.01, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "763f98a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_predictions(X, w1, b1, w2, b2, w3, b3):\n",
    "    _, _, _, _, _, a3 = forward_prop(w1, b1, w2, b2, w3, b3, X)\n",
    "    predictions = get_predictions(a3)\n",
    "    return predictions\n",
    "\n",
    "def test_predictions(index, w1, b1, w2, b2, w3, b3):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], w1, b1, w2, b2, w3, b3)\n",
    "    label = y_train[index]\n",
    "    print('Prediction: ', prediction)\n",
    "    print('Label: ', label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation = 'nearest')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a6786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [24]\n",
      "Label:  24\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions(6589, w1, b1, w2, b2, w3, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2902deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  0  0 ... 25 25 25] [ 0  0  0 ... 25 25 25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7476923076923077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = make_predictions(X_test, w1, b1, w2, b2, w3, b3)\n",
    "get_accuracy(test_predictions, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
